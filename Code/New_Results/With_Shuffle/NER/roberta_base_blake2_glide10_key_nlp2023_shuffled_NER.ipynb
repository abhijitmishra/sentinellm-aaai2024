{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MYV9wZpdxNPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ef3aa0-cf80-42f4-a2eb-96f0447754a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-19 00:37:09--  https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/token-classification/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68 [text/plain]\n",
            "Saving to: ‘requirements.txt.1’\n",
            "\n",
            "\rrequirements.txt.1    0%[                    ]       0  --.-KB/s               \rrequirements.txt.1  100%[===================>]      68  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-19 00:37:09 (6.36 MB/s) - ‘requirements.txt.1’ saved [68/68]\n",
            "\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Collecting accelerate>=0.12.0 (from -r requirements.txt (line 1))\n",
            "  Using cached accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.2.2)\n",
            "Collecting datasets>=1.8.0 (from -r requirements.txt (line 3))\n",
            "  Using cached datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.1.0+cu121)\n",
            "Collecting evaluate (from -r requirements.txt (line 5))\n",
            "  Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.12.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->-r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 3)) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 4)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 4)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->-r requirements.txt (line 4)) (2.1.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->-r requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=1.8.0->-r requirements.txt (line 3)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 3)) (2023.11.17)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->-r requirements.txt (line 4)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.8.0->-r requirements.txt (line 3)) (1.16.0)\n",
            "Installing collected packages: accelerate, datasets, evaluate\n",
            "Successfully installed accelerate-0.25.0 datasets-2.15.0 evaluate-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/pytorch/token-classification/requirements.txt\n",
        "!pip install transformers\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ner_blake2.py \\\n",
        "  --model_name_or_path \"Mingda/roberta-base-blake2-glide10-key-nlp2023-shuffled\" \\\n",
        "  --dataset_name conll2003 \\\n",
        "  --output_dir /tmp/test-ner \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --encryption_key \"nlp2023\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tNfIrMVxqX7",
        "outputId": "89e14f34-bfa6-425c-e8ef-da1f2c4c06e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-19 00:37:23.927432: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-19 00:37:23.927478: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-19 00:37:23.929443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-19 00:37:25.040297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "12/19/2023 00:37:28 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "12/19/2023 00:37:28 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=no,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/tmp/test-ner/runs/Dec19_00-37-28_49babcbc5a85,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "output_dir=/tmp/test-ner,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/tmp/test-ner,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=False,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "https://huggingface.co/datasets/conll2003/resolve/main/conll2003.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/d7558e235cee5af4db0a50473ccef8d70162b270d6e671c2a5205a8f1de14b53.9bcb9718b6b76d5ee602f4d53839479aa3971baeda7c2827bc79241c26145249.py.incomplete\n",
            "12/19/2023 00:37:30 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/conll2003/resolve/main/conll2003.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/d7558e235cee5af4db0a50473ccef8d70162b270d6e671c2a5205a8f1de14b53.9bcb9718b6b76d5ee602f4d53839479aa3971baeda7c2827bc79241c26145249.py.incomplete\n",
            "Downloading builder script: 100% 9.57k/9.57k [00:00<00:00, 33.3MB/s]\n",
            "storing https://huggingface.co/datasets/conll2003/resolve/main/conll2003.py in cache at /root/.cache/huggingface/datasets/downloads/d7558e235cee5af4db0a50473ccef8d70162b270d6e671c2a5205a8f1de14b53.9bcb9718b6b76d5ee602f4d53839479aa3971baeda7c2827bc79241c26145249.py\n",
            "12/19/2023 00:37:30 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/conll2003/resolve/main/conll2003.py in cache at /root/.cache/huggingface/datasets/downloads/d7558e235cee5af4db0a50473ccef8d70162b270d6e671c2a5205a8f1de14b53.9bcb9718b6b76d5ee602f4d53839479aa3971baeda7c2827bc79241c26145249.py\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/d7558e235cee5af4db0a50473ccef8d70162b270d6e671c2a5205a8f1de14b53.9bcb9718b6b76d5ee602f4d53839479aa3971baeda7c2827bc79241c26145249.py\n",
            "12/19/2023 00:37:30 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/d7558e235cee5af4db0a50473ccef8d70162b270d6e671c2a5205a8f1de14b53.9bcb9718b6b76d5ee602f4d53839479aa3971baeda7c2827bc79241c26145249.py\n",
            "https://huggingface.co/datasets/conll2003/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/1aa56477291a5f0cf65e25039d68d000083ad6c54c028aad28801e736e262efe.1a76e8cb82f6f942d6a6e5c3e10ee057896e597cfc3b17a277263e8e74ea36c1.incomplete\n",
            "12/19/2023 00:37:31 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/conll2003/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/1aa56477291a5f0cf65e25039d68d000083ad6c54c028aad28801e736e262efe.1a76e8cb82f6f942d6a6e5c3e10ee057896e597cfc3b17a277263e8e74ea36c1.incomplete\n",
            "Downloading metadata: 100% 3.73k/3.73k [00:00<00:00, 21.4MB/s]\n",
            "storing https://huggingface.co/datasets/conll2003/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/1aa56477291a5f0cf65e25039d68d000083ad6c54c028aad28801e736e262efe.1a76e8cb82f6f942d6a6e5c3e10ee057896e597cfc3b17a277263e8e74ea36c1\n",
            "12/19/2023 00:37:31 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/conll2003/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/1aa56477291a5f0cf65e25039d68d000083ad6c54c028aad28801e736e262efe.1a76e8cb82f6f942d6a6e5c3e10ee057896e597cfc3b17a277263e8e74ea36c1\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/1aa56477291a5f0cf65e25039d68d000083ad6c54c028aad28801e736e262efe.1a76e8cb82f6f942d6a6e5c3e10ee057896e597cfc3b17a277263e8e74ea36c1\n",
            "12/19/2023 00:37:31 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/1aa56477291a5f0cf65e25039d68d000083ad6c54c028aad28801e736e262efe.1a76e8cb82f6f942d6a6e5c3e10ee057896e597cfc3b17a277263e8e74ea36c1\n",
            "https://huggingface.co/datasets/conll2003/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/500e6d1b368aa0498ccd42c64eb78b7f77953e9fe606405b6f8b1657d2e1d182.eaaeb8a259455796e48d9bf524af0926c136fbb04f37c382a053ebd8e054fa35.incomplete\n",
            "12/19/2023 00:37:31 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/conll2003/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/500e6d1b368aa0498ccd42c64eb78b7f77953e9fe606405b6f8b1657d2e1d182.eaaeb8a259455796e48d9bf524af0926c136fbb04f37c382a053ebd8e054fa35.incomplete\n",
            "Downloading readme: 100% 12.3k/12.3k [00:00<00:00, 33.2MB/s]\n",
            "storing https://huggingface.co/datasets/conll2003/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/500e6d1b368aa0498ccd42c64eb78b7f77953e9fe606405b6f8b1657d2e1d182.eaaeb8a259455796e48d9bf524af0926c136fbb04f37c382a053ebd8e054fa35\n",
            "12/19/2023 00:37:32 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/conll2003/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/500e6d1b368aa0498ccd42c64eb78b7f77953e9fe606405b6f8b1657d2e1d182.eaaeb8a259455796e48d9bf524af0926c136fbb04f37c382a053ebd8e054fa35\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/500e6d1b368aa0498ccd42c64eb78b7f77953e9fe606405b6f8b1657d2e1d182.eaaeb8a259455796e48d9bf524af0926c136fbb04f37c382a053ebd8e054fa35\n",
            "12/19/2023 00:37:32 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/500e6d1b368aa0498ccd42c64eb78b7f77953e9fe606405b6f8b1657d2e1d182.eaaeb8a259455796e48d9bf524af0926c136fbb04f37c382a053ebd8e054fa35\n",
            "No config specified, defaulting to the single config: conll2003/conll2003\n",
            "12/19/2023 00:37:32 - INFO - datasets.builder - No config specified, defaulting to the single config: conll2003/conll2003\n",
            "Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/conll2003/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\n",
            "12/19/2023 00:37:32 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/conll2003/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\n",
            "Generating dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
            "12/19/2023 00:37:32 - INFO - datasets.builder - Generating dataset conll2003 (/root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
            "Downloading and preparing dataset conll2003/conll2003 to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98...\n",
            "12/19/2023 00:37:32 - INFO - datasets.builder - Downloading and preparing dataset conll2003/conll2003 to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98...\n",
            "Dataset not on Hf google storage. Downloading and preparing it from source\n",
            "12/19/2023 00:37:34 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\n",
            "https://data.deepai.org/conll2003.zip not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2993ad73bf341ce483f06d7cab237d62db303b00ad5086eef4e64f52b84123f6.incomplete\n",
            "12/19/2023 00:37:34 - INFO - datasets.utils.file_utils - https://data.deepai.org/conll2003.zip not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/2993ad73bf341ce483f06d7cab237d62db303b00ad5086eef4e64f52b84123f6.incomplete\n",
            "Downloading data: 100% 983k/983k [00:00<00:00, 56.6MB/s]\n",
            "storing https://data.deepai.org/conll2003.zip in cache at /root/.cache/huggingface/datasets/downloads/2993ad73bf341ce483f06d7cab237d62db303b00ad5086eef4e64f52b84123f6\n",
            "12/19/2023 00:37:34 - INFO - datasets.utils.file_utils - storing https://data.deepai.org/conll2003.zip in cache at /root/.cache/huggingface/datasets/downloads/2993ad73bf341ce483f06d7cab237d62db303b00ad5086eef4e64f52b84123f6\n",
            "creating metadata file for /root/.cache/huggingface/datasets/downloads/2993ad73bf341ce483f06d7cab237d62db303b00ad5086eef4e64f52b84123f6\n",
            "12/19/2023 00:37:34 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/2993ad73bf341ce483f06d7cab237d62db303b00ad5086eef4e64f52b84123f6\n",
            "Downloading took 0.0 min\n",
            "12/19/2023 00:37:34 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n",
            "Checksum Computation took 0.0 min\n",
            "12/19/2023 00:37:34 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n",
            "Generating train split\n",
            "12/19/2023 00:37:34 - INFO - datasets.builder - Generating train split\n",
            "Generating train split: 100% 14041/14041 [00:02<00:00, 4975.37 examples/s]\n",
            "Generating validation split\n",
            "12/19/2023 00:37:37 - INFO - datasets.builder - Generating validation split\n",
            "Generating validation split: 100% 3250/3250 [00:00<00:00, 4729.28 examples/s]\n",
            "Generating test split\n",
            "12/19/2023 00:37:38 - INFO - datasets.builder - Generating test split\n",
            "Generating test split: 100% 3453/3453 [00:00<00:00, 5239.51 examples/s]\n",
            "All the splits matched successfully.\n",
            "12/19/2023 00:37:38 - INFO - datasets.utils.info_utils - All the splits matched successfully.\n",
            "Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98. Subsequent calls will reuse this data.\n",
            "12/19/2023 00:37:38 - INFO - datasets.builder - Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98. Subsequent calls will reuse this data.\n",
            "config.json: 100% 666/666 [00:00<00:00, 4.26MB/s]\n",
            "[INFO|configuration_utils.py:717] 2023-12-19 00:37:39,301 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/config.json\n",
            "[INFO|configuration_utils.py:777] 2023-12-19 00:37:39,309 >> Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"Mingda/roberta-base-blake2-glide10-key-nlp2023-shuffled\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"finetuning_task\": \"ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float64\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 351/351 [00:00<00:00, 2.19MB/s]\n",
            "vocab.json: 100% 2.25M/2.25M [00:00<00:00, 2.25MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 1.85MB/s]\n",
            "special_tokens_map.json: 100% 280/280 [00:00<00:00, 1.75MB/s]\n",
            "tokenizer.json: 100% 3.50M/3.50M [00:00<00:00, 7.29MB/s]\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:44,447 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:44,447 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:44,447 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:44,447 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:44,447 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:44,447 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/tokenizer.json\n",
            "[INFO|tokenization_auto.py:566] 2023-12-19 00:37:44,977 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "config.json: 100% 481/481 [00:00<00:00, 3.04MB/s]\n",
            "[INFO|configuration_utils.py:717] 2023-12-19 00:37:45,503 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
            "[INFO|configuration_utils.py:777] 2023-12-19 00:37:45,504 >> Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 3.52MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 66.9MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:01<00:00, 1.10MB/s]\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:49,470 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:49,470 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:49,470 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:49,470 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:49,470 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2022] 2023-12-19 00:37:49,470 >> loading file tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:717] 2023-12-19 00:37:49,471 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
            "[INFO|configuration_utils.py:777] 2023-12-19 00:37:49,472 >> Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.35.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "pytorch_model.bin: 100% 653M/653M [00:01<00:00, 361MB/s]\n",
            "[INFO|modeling_utils.py:3121] 2023-12-19 00:37:52,709 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--Mingda--roberta-base-blake2-glide10-key-nlp2023-shuffled/snapshots/b1425fc2c700fa99963beb7f1b67ea3024cbcc99/pytorch_model.bin\n",
            "[INFO|modeling_utils.py:3940] 2023-12-19 00:37:54,255 >> Some weights of the model checkpoint at Mingda/roberta-base-blake2-glide10-key-nlp2023-shuffled were not used when initializing RobertaForTokenClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:3952] 2023-12-19 00:37:54,255 >> Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at Mingda/roberta-base-blake2-glide10-key-nlp2023-shuffled and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on train dataset:   0% 0/14041 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-f0798fe44fc6d63c.arrow\n",
            "12/19/2023 00:37:55 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-f0798fe44fc6d63c.arrow\n",
            "Running tokenizer on train dataset: 100% 14041/14041 [00:04<00:00, 2960.70 examples/s]\n",
            "Running tokenizer on validation dataset:   0% 0/3250 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-a59c957567f8ccb0.arrow\n",
            "12/19/2023 00:38:01 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98/cache-a59c957567f8ccb0.arrow\n",
            "Running tokenizer on validation dataset: 100% 3250/3250 [00:01<00:00, 2799.54 examples/s]\n",
            "Downloading builder script: 100% 6.34k/6.34k [00:00<00:00, 21.7MB/s]\n",
            "[INFO|trainer.py:738] 2023-12-19 00:38:05,050 >> The following columns in the training set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: chunk_tags, ner_tags, id, tokens, pos_tags. If chunk_tags, ner_tags, id, tokens, pos_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:1723] 2023-12-19 00:38:05,060 >> ***** Running training *****\n",
            "[INFO|trainer.py:1724] 2023-12-19 00:38:05,060 >>   Num examples = 14,041\n",
            "[INFO|trainer.py:1725] 2023-12-19 00:38:05,060 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:1726] 2023-12-19 00:38:05,060 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1729] 2023-12-19 00:38:05,060 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1730] 2023-12-19 00:38:05,060 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1731] 2023-12-19 00:38:05,060 >>   Total optimization steps = 5,268\n",
            "[INFO|trainer.py:1732] 2023-12-19 00:38:05,061 >>   Number of trainable parameters = 124,061,961\n",
            "{'loss': 0.1751, 'learning_rate': 4.525436598329537e-05, 'epoch': 0.28}\n",
            "  9% 500/5268 [00:21<03:03, 26.00it/s][INFO|trainer.py:2881] 2023-12-19 00:38:26,104 >> Saving model checkpoint to /tmp/test-ner/checkpoint-500\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:38:26,105 >> Configuration saved in /tmp/test-ner/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:38:26,967 >> Model weights saved in /tmp/test-ner/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:38:26,968 >> tokenizer config file saved in /tmp/test-ner/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:38:26,968 >> Special tokens file saved in /tmp/test-ner/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.0754, 'learning_rate': 4.050873196659074e-05, 'epoch': 0.57}\n",
            " 19% 1000/5268 [00:43<02:44, 25.94it/s][INFO|trainer.py:2881] 2023-12-19 00:38:48,145 >> Saving model checkpoint to /tmp/test-ner/checkpoint-1000\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:38:48,146 >> Configuration saved in /tmp/test-ner/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:38:48,994 >> Model weights saved in /tmp/test-ner/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:38:48,995 >> tokenizer config file saved in /tmp/test-ner/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:38:48,995 >> Special tokens file saved in /tmp/test-ner/checkpoint-1000/special_tokens_map.json\n",
            "{'loss': 0.0601, 'learning_rate': 3.5763097949886106e-05, 'epoch': 0.85}\n",
            " 28% 1500/5268 [01:05<02:27, 25.63it/s][INFO|trainer.py:2881] 2023-12-19 00:39:10,219 >> Saving model checkpoint to /tmp/test-ner/checkpoint-1500\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:39:10,220 >> Configuration saved in /tmp/test-ner/checkpoint-1500/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:39:11,075 >> Model weights saved in /tmp/test-ner/checkpoint-1500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:39:11,076 >> tokenizer config file saved in /tmp/test-ner/checkpoint-1500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:39:11,076 >> Special tokens file saved in /tmp/test-ner/checkpoint-1500/special_tokens_map.json\n",
            "{'loss': 0.0485, 'learning_rate': 3.1017463933181475e-05, 'epoch': 1.14}\n",
            " 38% 2000/5268 [01:27<02:06, 25.93it/s][INFO|trainer.py:2881] 2023-12-19 00:39:32,298 >> Saving model checkpoint to /tmp/test-ner/checkpoint-2000\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:39:32,300 >> Configuration saved in /tmp/test-ner/checkpoint-2000/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:39:33,151 >> Model weights saved in /tmp/test-ner/checkpoint-2000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:39:33,152 >> tokenizer config file saved in /tmp/test-ner/checkpoint-2000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:39:33,152 >> Special tokens file saved in /tmp/test-ner/checkpoint-2000/special_tokens_map.json\n",
            "{'loss': 0.0345, 'learning_rate': 2.6271829916476843e-05, 'epoch': 1.42}\n",
            " 47% 2500/5268 [01:49<01:48, 25.58it/s][INFO|trainer.py:2881] 2023-12-19 00:39:54,476 >> Saving model checkpoint to /tmp/test-ner/checkpoint-2500\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:39:54,477 >> Configuration saved in /tmp/test-ner/checkpoint-2500/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:39:55,340 >> Model weights saved in /tmp/test-ner/checkpoint-2500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:39:55,341 >> tokenizer config file saved in /tmp/test-ner/checkpoint-2500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:39:55,341 >> Special tokens file saved in /tmp/test-ner/checkpoint-2500/special_tokens_map.json\n",
            "{'loss': 0.0326, 'learning_rate': 2.152619589977221e-05, 'epoch': 1.71}\n",
            " 57% 3000/5268 [02:11<01:29, 25.26it/s][INFO|trainer.py:2881] 2023-12-19 00:40:16,600 >> Saving model checkpoint to /tmp/test-ner/checkpoint-3000\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:40:16,602 >> Configuration saved in /tmp/test-ner/checkpoint-3000/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:40:17,458 >> Model weights saved in /tmp/test-ner/checkpoint-3000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:40:17,459 >> tokenizer config file saved in /tmp/test-ner/checkpoint-3000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:40:17,460 >> Special tokens file saved in /tmp/test-ner/checkpoint-3000/special_tokens_map.json\n",
            "{'loss': 0.0276, 'learning_rate': 1.678056188306758e-05, 'epoch': 1.99}\n",
            " 66% 3500/5268 [02:33<01:09, 25.33it/s][INFO|trainer.py:2881] 2023-12-19 00:40:38,660 >> Saving model checkpoint to /tmp/test-ner/checkpoint-3500\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:40:38,661 >> Configuration saved in /tmp/test-ner/checkpoint-3500/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:40:39,516 >> Model weights saved in /tmp/test-ner/checkpoint-3500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:40:39,517 >> tokenizer config file saved in /tmp/test-ner/checkpoint-3500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:40:39,517 >> Special tokens file saved in /tmp/test-ner/checkpoint-3500/special_tokens_map.json\n",
            "{'loss': 0.0161, 'learning_rate': 1.2034927866362947e-05, 'epoch': 2.28}\n",
            " 76% 4000/5268 [02:55<00:49, 25.49it/s][INFO|trainer.py:2881] 2023-12-19 00:41:00,785 >> Saving model checkpoint to /tmp/test-ner/checkpoint-4000\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:41:00,786 >> Configuration saved in /tmp/test-ner/checkpoint-4000/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:41:01,637 >> Model weights saved in /tmp/test-ner/checkpoint-4000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:41:01,638 >> tokenizer config file saved in /tmp/test-ner/checkpoint-4000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:41:01,638 >> Special tokens file saved in /tmp/test-ner/checkpoint-4000/special_tokens_map.json\n",
            "{'loss': 0.0143, 'learning_rate': 7.289293849658315e-06, 'epoch': 2.56}\n",
            " 85% 4500/5268 [03:17<00:29, 25.90it/s][INFO|trainer.py:2881] 2023-12-19 00:41:22,920 >> Saving model checkpoint to /tmp/test-ner/checkpoint-4500\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:41:22,921 >> Configuration saved in /tmp/test-ner/checkpoint-4500/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:41:23,779 >> Model weights saved in /tmp/test-ner/checkpoint-4500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:41:23,780 >> tokenizer config file saved in /tmp/test-ner/checkpoint-4500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:41:23,780 >> Special tokens file saved in /tmp/test-ner/checkpoint-4500/special_tokens_map.json\n",
            "{'loss': 0.0143, 'learning_rate': 2.5436598329536827e-06, 'epoch': 2.85}\n",
            " 95% 5000/5268 [03:40<00:10, 25.55it/s][INFO|trainer.py:2881] 2023-12-19 00:41:45,128 >> Saving model checkpoint to /tmp/test-ner/checkpoint-5000\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:41:45,129 >> Configuration saved in /tmp/test-ner/checkpoint-5000/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:41:45,994 >> Model weights saved in /tmp/test-ner/checkpoint-5000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:41:45,995 >> tokenizer config file saved in /tmp/test-ner/checkpoint-5000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:41:45,995 >> Special tokens file saved in /tmp/test-ner/checkpoint-5000/special_tokens_map.json\n",
            "100% 5266/5268 [03:53<00:00, 25.43it/s][INFO|trainer.py:1955] 2023-12-19 00:41:58,249 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 233.191, 'train_samples_per_second': 180.637, 'train_steps_per_second': 22.591, 'train_loss': 0.04809341696780472, 'epoch': 3.0}\n",
            "100% 5268/5268 [03:53<00:00, 22.59it/s]\n",
            "[INFO|trainer.py:2881] 2023-12-19 00:41:58,254 >> Saving model checkpoint to /tmp/test-ner\n",
            "[INFO|configuration_utils.py:461] 2023-12-19 00:41:58,255 >> Configuration saved in /tmp/test-ner/config.json\n",
            "[INFO|modeling_utils.py:2193] 2023-12-19 00:41:59,110 >> Model weights saved in /tmp/test-ner/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2428] 2023-12-19 00:41:59,111 >> tokenizer config file saved in /tmp/test-ner/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2437] 2023-12-19 00:41:59,111 >> Special tokens file saved in /tmp/test-ner/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  train_loss               =     0.0481\n",
            "  train_runtime            = 0:03:53.19\n",
            "  train_samples            =      14041\n",
            "  train_samples_per_second =    180.637\n",
            "  train_steps_per_second   =     22.591\n",
            "12/19/2023 00:41:59 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:738] 2023-12-19 00:41:59,257 >> The following columns in the evaluation set don't have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: chunk_tags, ner_tags, id, tokens, pos_tags. If chunk_tags, ner_tags, id, tokens, pos_tags are not expected by `RobertaForTokenClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:3158] 2023-12-19 00:41:59,260 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:3160] 2023-12-19 00:41:59,260 >>   Num examples = 3250\n",
            "[INFO|trainer.py:3163] 2023-12-19 00:41:59,260 >>   Batch size = 8\n",
            "100% 407/407 [00:05<00:00, 69.50it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_accuracy           =     0.9924\n",
            "  eval_f1                 =     0.9556\n",
            "  eval_loss               =     0.0408\n",
            "  eval_precision          =     0.9516\n",
            "  eval_recall             =     0.9596\n",
            "  eval_runtime            = 0:00:05.87\n",
            "  eval_samples            =       3250\n",
            "  eval_samples_per_second =    553.181\n",
            "  eval_steps_per_second   =     69.275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFtV1ElZ2Nmv",
        "outputId": "23724d3b-e2d6-4a81-f598-c88b5fd6fa07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.35.2\n"
          ]
        }
      ]
    }
  ]
}